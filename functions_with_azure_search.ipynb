{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function calling with Azure Cognitive Search\n",
    "\n",
    "In this notebook, we'll show how to create a simple chatbot to help you find or create a good recipe. We'll create an index in Azure Cognitive Search using [vector search](), and then use use [function calling]() to write queries to the index.\n",
    "\n",
    "All of the recipes used in this sample were generated by gpt-35-turbo for demo purposes. The recipes are not guaranteed to be safe or taste good so we don't recommend trying them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install azure-search-documents==11.4.0b6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "import json  \n",
    "import openai  \n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt  \n",
    "from azure.core.credentials import AzureKeyCredential  \n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient  \n",
    "from azure.search.documents.models import Vector\n",
    "from azure.search.documents.indexes.models import (  \n",
    "    SearchIndex,  \n",
    "    SearchField,  \n",
    "    SearchFieldDataType,  \n",
    "    SimpleField,  \n",
    "    SearchableField,  \n",
    "    SearchIndex,  \n",
    "    SemanticConfiguration,  \n",
    "    PrioritizedFields,  \n",
    "    SemanticField,  \n",
    "    SearchField,  \n",
    "    SemanticSettings,  \n",
    "    VectorSearch,  \n",
    "    VectorSearchAlgorithmConfiguration,  \n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config values\n",
    "with open(r'config.json') as config_file:\n",
    "    config_details = json.load(config_file)\n",
    "    \n",
    "# Configure environment variables for Azure Cognitive Search\n",
    "service_endpoint = config_details[\"SEARCH_SERVICE_ENDPOINT\"]\n",
    "index_name = config_details[\"SEARCH_INDEX_NAME\"]\n",
    "key = config_details[\"SEARCH_ADMIN_KEY\"]\n",
    "credential = AzureKeyCredential(key)\n",
    "\n",
    "# Create the Azure Cognitive Search client to issue queries\n",
    "search_client = SearchClient(endpoint=service_endpoint, index_name=index_name, credential=credential)\n",
    "\n",
    "# Create the index client\n",
    "index_client = SearchIndexClient(endpoint=service_endpoint, credential=credential)\n",
    "\n",
    "# Configure OpenAI environment variables\n",
    "openai.api_key = config_details['OPENAI_API_KEY']#os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_base = config_details['OPENAI_API_BASE']\n",
    "openai.api_type = \"azure\"  \n",
    "openai.api_version = config_details['OPENAI_API_VERSION']\n",
    "\n",
    "deployment_name = config_details['DEPLOYMENT_NAME'] # You need to use the 0613 version of gpt-35-turbo or gpt-4 to work with functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Create the search index and load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " recipes-vectors deleted\n",
      " recipes-vectors created\n"
     ]
    }
   ],
   "source": [
    "# Create a search index\n",
    "fields = [\n",
    "    SimpleField(name=\"recipe_id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True),\n",
    "    SearchableField(name=\"recipe_category\", type=SearchFieldDataType.String, filterable=True, analyzer_name=\"en.microsoft\"),    \n",
    "    SearchableField(name=\"recipe_name\", type=SearchFieldDataType.String, facetable=True, analyzer_name=\"en.microsoft\"),\n",
    "    SearchableField(name=\"ingredients\", collection=True, type=SearchFieldDataType.String, facetable=True, filterable=True),\n",
    "    SearchableField(name=\"recipe\", type=SearchFieldDataType.String, analyzer_name=\"en.microsoft\"),\n",
    "    SearchableField(name=\"description\", type=SearchFieldDataType.String, analyzer_name=\"en.microsoft\"),\n",
    "    SimpleField(name=\"total_time\", type=SearchFieldDataType.Int32, filterable=True, facetable=True),\n",
    "    SearchField(name=\"recipe_vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                searchable=True, vector_search_dimensions=1536, vector_search_configuration=\"my-vector-config\")\n",
    "]\n",
    "\n",
    "vector_search = VectorSearch(\n",
    "    algorithm_configurations=[\n",
    "        VectorSearchAlgorithmConfiguration(\n",
    "            name=\"my-vector-config\",\n",
    "            kind=\"hnsw\",\n",
    "            hnsw_parameters={\n",
    "                \"m\": 4,\n",
    "                \"efConstruction\": 400,\n",
    "                \"efSearch\": 500,\n",
    "                \"metric\": \"cosine\"\n",
    "            }\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Semantic Configuration to leverage Bing family of ML models for re-ranking (L2)\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"my-semantic-config\",\n",
    "    prioritized_fields=PrioritizedFields(\n",
    "        title_field=None,\n",
    "        prioritized_keywords_fields=[],\n",
    "        prioritized_content_fields=[SemanticField(field_name=\"recipe\")]\n",
    "    ))\n",
    "semantic_settings = SemanticSettings(configurations=[semantic_config])\n",
    "\n",
    "\n",
    "# Create the search index with the semantic settings\n",
    "index = SearchIndex(name=index_name, fields=fields, \n",
    "                    vector_search=vector_search, semantic_settings=semantic_settings)\n",
    "result = index_client.delete_index(index)\n",
    "print(f' {index_name} deleted')\n",
    "result = index_client.create_index(index)\n",
    "print(f' {result.name} created')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a helper function to create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate embeddings for title and content fields, also used for query embeddings\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "def generate_embeddings(text):\n",
    "    response = openai.Embedding.create(\n",
    "        input=text, engine=\"text-embedding-ada-002\")\n",
    "    embeddings = response['data'][0]['embedding']\n",
    "    return embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data into Azure Cognitive Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 100 documents\n",
      "Uploaded 100 documents\n",
      "Uploaded 100 documents\n",
      "Uploaded 100 documents\n",
      "Uploaded 3 documents\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "counter = 0\n",
    "documents = []\n",
    "search_client = SearchClient(endpoint=service_endpoint, index_name=index_name, credential=credential)\n",
    "\n",
    "with open(\"recipes_final.jsonl\", \"r\") as j_in:\n",
    "    for line in j_in:\n",
    "        counter += 1 \n",
    "        json_recipe = json.loads(line)\n",
    "        json_recipe['total_time'] = int(json_recipe['total_time'].split(' ')[0])\n",
    "        json_recipe['recipe_vector'] = generate_embeddings(json_recipe['recipe'])\n",
    "        json_recipe[\"@search.action\"] = \"upload\"\n",
    "        documents.append(json_recipe)\n",
    "        if counter % batch_size == 0:\n",
    "            # Load content into index\n",
    "            result = search_client.upload_documents(documents)  \n",
    "            print(f\"Uploaded {len(documents)} documents\") \n",
    "            documents = []\n",
    "            \n",
    "            \n",
    "if documents != []:\n",
    "    # Load content into index\n",
    "    result = search_client.upload_documents(documents)  \n",
    "    print(f\"Uploaded {len(documents)} documents\") \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Test function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 43\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39m# messages = [{\"role\": \"user\", \"content\": \"Help me find a good mexican recipe that has beans and rice\"}]\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m# messages = [{\"role\": \"user\", \"content\": \"What should I cook for dinner?\"}]\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m# messages = [{\"role\": \"system\", \"content\": system_message},\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39m#            {\"role\": \"user\", \"content\": \"find an easy mexican recipe with beans and rice\"}]\u001b[39;00m\n\u001b[0;32m     18\u001b[0m functions \u001b[39m=\u001b[39m [\n\u001b[0;32m     19\u001b[0m     {\n\u001b[0;32m     20\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mquery_recipes\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     40\u001b[0m     }\n\u001b[0;32m     41\u001b[0m ]\n\u001b[1;32m---> 43\u001b[0m response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m     44\u001b[0m     deployment_id\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-35-turbo-0613\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     45\u001b[0m     messages\u001b[39m=\u001b[39;49mmessages,\n\u001b[0;32m     46\u001b[0m     functions\u001b[39m=\u001b[39;49mfunctions,\n\u001b[0;32m     47\u001b[0m     temperature\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m,\n\u001b[0;32m     48\u001b[0m     function_call\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mauto\u001b[39;49m\u001b[39m\"\u001b[39;49m, \n\u001b[0;32m     49\u001b[0m )\n\u001b[0;32m     51\u001b[0m \u001b[39mprint\u001b[39m(response[\u001b[39m'\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32md:\\Users\\2303906\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[1;32md:\\Users\\2303906\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32md:\\Users\\2303906\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    279\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    289\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    290\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    297\u001b[0m     )\n\u001b[1;32m--> 298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32md:\\Users\\2303906\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    693\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    694\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    695\u001b[0m         )\n\u001b[0;32m    696\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    697\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    698\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 700\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    701\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    702\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    703\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    704\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    705\u001b[0m         ),\n\u001b[0;32m    706\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    707\u001b[0m     )\n",
      "File \u001b[1;32md:\\Users\\2303906\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\api_requestor.py:763\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    761\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    762\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 763\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    764\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    765\u001b[0m     )\n\u001b[0;32m    766\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mInvalidRequestError\u001b[0m: The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again."
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"Help me find a good lasagna recipe.\"}]\n",
    "    \n",
    "# messages = [{\"role\": \"user\", \"content\": \"Help me find a good mexican recipe that has beans and rice\"}]\n",
    "# messages = [{\"role\": \"user\", \"content\": \"What should I cook for dinner?\"}]\n",
    "\n",
    "### Try again with a more detailed system message ###\n",
    "# system_message = \"\"\"Assistant is a large language model designed to help users find and create recipes.\n",
    "# You have access to an Azure Cognitive Search index with hundreds of recipes. You can search for recipes by name, ingredient, or cuisine.\n",
    "# You are designed to be an interactive assistant, so you can ask users clarifying questions to help them find the right recipe. It's better to give more detailed queries to the search index rather than vague one.\n",
    "# \"\"\"\n",
    "\n",
    "# messages = [{\"role\": \"system\", \"content\": system_message},\n",
    "#             {\"role\": \"user\", \"content\": \"What should I cook for dinner?\"}]\n",
    "\n",
    "# messages = [{\"role\": \"system\", \"content\": system_message},\n",
    "#            {\"role\": \"user\", \"content\": \"find an easy mexican recipe with beans and rice\"}]\n",
    "                \n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"query_recipes\",\n",
    "        \"description\": \"Retrieve recipes from the Azure Cognitive Search index\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The query string to search for recipes\",\n",
    "                },\n",
    "                \"ingredients_filter\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The odata filter to apply for the ingredients field. Only actual ingredient names should be used in this filter. If you're not sure something is an ingredient, don't include this filter. Example: ingredients/any(i: i eq 'salt' or i eq 'pepper')\",\n",
    "                },\n",
    "                \"time_filter\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The odata filter to apply for the total_time field. If a user asks for a quick or easy recipe, you should filter down to recipes that will take less than 30 minutes. Example: total_time lt 25\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"query\"],\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    deployment_id=\"gpt-4-32k\",\n",
    "    messages=messages,\n",
    "    functions=functions,\n",
    "    temperature=0.2,\n",
    "    function_call=\"auto\", \n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to call Azure Cognitive Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_recipes(query, ingredients_filter=None, time_filter=None):\n",
    "    filter = \"\"\n",
    "    if ingredients_filter and time_filter:\n",
    "        filter = f\"{time_filter} and {ingredients_filter}\"\n",
    "    elif ingredients_filter:\n",
    "        filter = ingredients_filter\n",
    "    elif time_filter:\n",
    "        filter = time_filter\n",
    "\n",
    "\n",
    "    results = search_client.search(  \n",
    "        query_type=\"semantic\",\n",
    "        query_language=\"en-us\",\n",
    "        semantic_configuration_name=\"my-semantic-config\",\n",
    "        search_text=query,  \n",
    "        vector=generate_embeddings(query),\n",
    "        filter=filter,\n",
    "        top_k=3, \n",
    "        vector_fields=\"recipe_vector\",\n",
    "        select=[\"recipe_id\", \"recipe\", \"recipe_category\", \"recipe_name\", \"description\"],\n",
    "        top=3\n",
    "    )  \n",
    "   \n",
    "    n = 1\n",
    "    recipes_for_prompt = \"\"\n",
    "    for result in results:\n",
    "        recipes_for_prompt += f\"Recipe {result['recipe_id']}: {result['recipe_name']}: {result['description']}\\n\"\n",
    "        n += 1\n",
    "\n",
    "    return recipes_for_prompt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Get things running end to end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_conversation(messages, functions, available_functions, deployment_id):\n",
    "    \n",
    "    # Step 1: send the conversation and available functions to GPT\n",
    "    response = openai.ChatCompletion.create(\n",
    "        deployment_id=deployment_id,\n",
    "        messages=messages,\n",
    "        functions=functions,\n",
    "        function_call=\"auto\", \n",
    "        temperature=0.2\n",
    "    )\n",
    "    response_message = response[\"choices\"][0][\"message\"]\n",
    "\n",
    "\n",
    "    # Step 2: check if the model wants to call a function\n",
    "    if response_message.get(\"function_call\"):\n",
    "        print(\"Recommended Function call:\")\n",
    "        print(response_message.get(\"function_call\"))\n",
    "        print()\n",
    "        \n",
    "        # Step 3: call the function\n",
    "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "        function_name = response_message[\"function_call\"][\"name\"]\n",
    "        \n",
    "        # verify function exists\n",
    "        if function_name not in available_functions:\n",
    "            return \"Function \" + function_name + \" does not exist\"\n",
    "        function_to_call = available_functions[function_name]  \n",
    "        \n",
    "        function_args = json.loads(response_message[\"function_call\"][\"arguments\"])\n",
    "        function_response = function_to_call(**function_args)\n",
    "        \n",
    "        print(\"Output of function call:\")\n",
    "        print(function_response)\n",
    "        print()\n",
    "        \n",
    "        # Step 4: send the info on the function call and function response to the model\n",
    "        \n",
    "        # adding assistant response to messages\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": response_message[\"role\"],\n",
    "                \"function_call\": {\n",
    "                    \"name\": response_message[\"function_call\"][\"name\"],\n",
    "                    \"arguments\": response_message[\"function_call\"][\"arguments\"],\n",
    "                },\n",
    "                \"content\": None\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # adding function response to messages\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"function\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            }\n",
    "        )  # extend conversation with function response\n",
    "\n",
    "        print(\"Messages in second request:\")\n",
    "        for message in messages:\n",
    "            print(message)\n",
    "        print()\n",
    "\n",
    "        second_response = openai.ChatCompletion.create(\n",
    "            messages=messages,\n",
    "            deployment_id=deployment_id\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "        return second_response\n",
    "    else:\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"Assistant is a large language model designed to help users find and create recipes.\n",
    "\n",
    "You have access to an Azure Cognitive Search index with hundreds of recipes. You can search for recipes by name, ingredient, or cuisine.\n",
    "\n",
    "You are designed to be an interactive assistant, so you can ask users clarifying questions to help them find the right recipe. It's better to give more detailed queries to the search index rather than vague one.\n",
    "\"\"\"\n",
    "\n",
    "messages = [{\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": \"I want to make a pasta dish that takes less than 60 minutes to make.\"}]\n",
    "\n",
    "available_functions = {'query_recipes': query_recipes}\n",
    "\n",
    "result = run_conversation(messages, functions, available_functions, deployment_name)\n",
    "\n",
    "print(\"Final response:\")\n",
    "print(result['choices'][0]['message']['content'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Define additional functions\n",
    "\n",
    "Now that we have the `query_recipes` function defined, we can add additional functions to add more capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"query_recipes\",\n",
    "        \"description\": \"Retrieve recipes from the Azure Cognitive Search index\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The query string to search for recipes\",\n",
    "                },\n",
    "                \"time_filter\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The odata filter to apply for the total_time field. If a user asks for a quick or easy recipe, you should filter down to recipes that will take less than 30 minutes. Example: total_time lt 25\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"query\"],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"get_recipe\",\n",
    "        \"description\": \"Gets a recipe based on it's id\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"id\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The id of a recipe. Usually a number such as 3846\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"id\"],\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"convert_measurement\",\n",
    "        \"description\": \"converts a measurement from one unit to another for common cooking measurements\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"amount\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"The quantity of the measurement to convert.\",\n",
    "                },\n",
    "                \"from_unit\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The unit to convert the measurement from. Supported values are tablespoons, teaspoons, cups, and ounces.\",\n",
    "                },\n",
    "                \"to_unit\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The unit to convert the measurement to. Supported values are tablespoons, teaspoons, cups, and ounces.\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"amount\", \"from_unit\", \"to_unit\"],\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to convert common measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_measurement(amount, from_unit, to_unit):\n",
    "    conversions = {\n",
    "        \"tablespoons\": {\n",
    "            \"teaspoons\": 3,\n",
    "            \"cups\": 1/16,\n",
    "            \"ounces\": 1/2.667\n",
    "        },\n",
    "        \"teaspoons\": {\n",
    "            \"tablespoons\": 1/3,\n",
    "            \"cups\": 1/48,\n",
    "            \"ounces\": 1/6\n",
    "        },\n",
    "        \"cups\": {\n",
    "            \"tablespoons\": 16,\n",
    "            \"teaspoons\": 48,\n",
    "            \"ounces\": 8\n",
    "        },\n",
    "        \"ounces\": {\n",
    "            \"tablespoons\": 3,\n",
    "            \"teaspoons\": 6,\n",
    "            \"cups\": 1/8\n",
    "        }\n",
    "    }\n",
    "    if from_unit == to_unit:\n",
    "        return str(amount) + \" \" + to_unit\n",
    "    else:\n",
    "        conversion_factor = conversions[from_unit][to_unit]\n",
    "        converted_amount = amount * conversion_factor\n",
    "        return str(converted_amount) + \" \" + to_unit\n",
    "\n",
    "convert_measurement(1, from_unit=\"tablespoons\", to_unit=\"teaspoons\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to get recipes by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recipe(id):\n",
    "    return search_client.get_document(key=id)['recipe']\n",
    "\n",
    "get_recipe(\"151\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 Test more examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_functions = {'query_recipes': query_recipes, \n",
    "                       'get_recipe': get_recipe,    \n",
    "                       'convert_measurement': convert_measurement}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"Assistant is a large language model designed to help users find and create recipes.\n",
    "\n",
    "You have access to an Azure Cognitive Search index with hundreds of recipes. You can search for recipes by name, ingredient, or cuisine.\n",
    "\n",
    "You are designed to be an interactive assistant, so you can ask users clarifying questions to help them find the right recipe. It's better to give more detailed queries to the search index rather than vague one.\n",
    "\"\"\"\n",
    "\n",
    "messages = [{\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": \"How many cups is 2 tablespoons of butter?\"}]\n",
    "\n",
    "result = run_conversation(messages, functions, available_functions, deployment_name)\n",
    "\n",
    "print(\"Final response:\")\n",
    "print(result['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"Assistant is a large language model designed to help users find and create recipes.\n",
    "\n",
    "You have access to an Azure Cognitive Search index with hundreds of recipes. You can search for recipes by name, ingredient, or cuisine.\n",
    "\n",
    "You are designed to be an interactive assistant, so you can ask users clarifying questions to help them find the right recipe. It's better to give more detailed queries to the search index rather than vague one.\n",
    "\"\"\"\n",
    "\n",
    "messages = [{'role': 'system', 'content': system_message},\n",
    "            {'role': 'user', 'content': 'Help me find a Thai recipe I can cook in less than an hour'},\n",
    "            {'role': 'assistant', 'function_call': {'name': 'query_recipes', 'arguments': '{\\n  \"query\": \"Thai\",\\n  \"time_filter\": \"total_time lt 60\"\\n}'}, 'content': None},\n",
    "            {'role': 'function', 'name': 'query_recipes', 'content': \"Recipe 200: Thai Peanut Noodles: Thai Peanut Noodles is a delicious and flavorful dish that combines the creaminess of peanut butter with the tanginess of lime and the heat of chili. This dish is perfect for those who enjoy a balance of sweet, savory, and spicy flavors.\\nRecipe 206: Thai Cashew Tofu Stir-Fry: This Thai-inspired stir-fry is packed with flavor, combining crispy tofu, crunchy vegetables, and cashews in a savory sauce. It's a quick and delicious weeknight meal option.\\nRecipe 196: Thai Beef Salad: Thai Beef Salad is a refreshing and vibrant dish that combines tender beef with a tangy and spicy dressing, fresh herbs, and colorful vegetables.\\n\"},\n",
    "            {'role': 'assistant', 'content': \"Here are a few Thai recipes that you can cook in less than an hour:\\n\\n1. Thai Peanut Noodles: This dish combines the creaminess of peanut butter with the tanginess of lime and the heat of chili. It's a perfect balance of sweet, savory, and spicy flavors.\\n\\n2. Thai Cashew Tofu Stir-Fry: This stir-fry is packed with flavor, combining crispy tofu, crunchy vegetables, and cashews in a savory sauce. It's a quick and delicious option for a weeknight meal.\\n\\n3. Thai Beef Salad: This refreshing and vibrant salad combines tender beef with a tangy and spicy dressing, fresh herbs, and colorful vegetables.\\n\\nLet me know if you'd like more information about any of these recipes!\"},\n",
    "            {'role': 'user', 'content': 'Show me the thai peanut noodles recipe'}\n",
    "]\n",
    "\n",
    "result = run_conversation(messages, functions, available_functions, deployment_name)\n",
    "\n",
    "print(\"Final response:\")\n",
    "print(result['choices'][0]['message'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
